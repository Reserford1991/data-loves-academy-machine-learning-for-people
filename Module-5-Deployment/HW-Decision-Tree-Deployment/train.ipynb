{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3acb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c09a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather_model_dt.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload data and remode unnecessary columns\n",
    "\n",
    "train_csv = 'csv/weatherAUS.csv'\n",
    "raw_df = pd.read_csv(train_csv)\n",
    "raw_df.dropna(subset=['RainToday', 'RainTomorrow'], inplace=True)\n",
    "\n",
    "# split into train, test and validation datasets\n",
    "\n",
    "year = pd.to_datetime(raw_df.Date).dt.year\n",
    "\n",
    "train_df = raw_df[year < 2015]\n",
    "val_df = raw_df[year == 2015]\n",
    "test_df = raw_df[year > 2015]\n",
    "\n",
    "# Define input and target columns\n",
    "\n",
    "input_cols = list(train_df.columns)[1:-1]\n",
    "target_col = 'RainTomorrow'\n",
    "\n",
    "\n",
    "train_inputs = train_df[input_cols].copy()\n",
    "train_targets = train_df[target_col].copy()\n",
    "\n",
    "val_inputs = val_df[input_cols].copy()\n",
    "val_targets = val_df[target_col].copy()\n",
    "\n",
    "test_inputs = test_df[input_cols].copy()\n",
    "test_targets = test_df[target_col].copy()\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "\n",
    "numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = train_inputs.select_dtypes('object').columns.tolist()\n",
    "\n",
    "# Fill in abscent values\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "imputer.fit(train_inputs[numeric_cols])\n",
    "\n",
    "train_inputs[numeric_cols] = imputer.transform(train_inputs[numeric_cols])\n",
    "val_inputs[numeric_cols] = imputer.transform(val_inputs[numeric_cols])\n",
    "test_inputs[numeric_cols] = imputer.transform(test_inputs[numeric_cols])\n",
    "\n",
    "# Scaling of features\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_inputs[numeric_cols])\n",
    "\n",
    "train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols])\n",
    "val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols])\n",
    "test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])\n",
    "\n",
    "# One hot encoding\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoder.fit(train_inputs[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
    "val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
    "test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
    "\n",
    "train_encoded = pd.DataFrame(encoder.transform(train_inputs[categorical_cols]),\n",
    "                             columns=encoded_cols,\n",
    "                             index=train_inputs.index)\n",
    "val_encoded = pd.DataFrame(encoder.transform(val_inputs[categorical_cols]),\n",
    "                           columns=encoded_cols,\n",
    "                           index=val_inputs.index)\n",
    "test_encoded = pd.DataFrame(encoder.transform(test_inputs[categorical_cols]),\n",
    "                            columns=encoded_cols,\n",
    "                            index=test_inputs.index)\n",
    "\n",
    "# Drop original categorical columns\n",
    "train_inputs.drop(columns=categorical_cols, inplace=True)\n",
    "val_inputs.drop(columns=categorical_cols, inplace=True)\n",
    "test_inputs.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "# Add encoded columns\n",
    "train_inputs = pd.concat([train_inputs, train_encoded], axis=1)\n",
    "val_inputs = pd.concat([val_inputs, val_encoded], axis=1)\n",
    "test_inputs = pd.concat([test_inputs, test_encoded], axis=1)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(train_inputs, train_targets)\n",
    "\n",
    "# Save trained model to file\n",
    "\n",
    "aussie_rain = {\n",
    "    'model': model,\n",
    "    'imputer': imputer,\n",
    "    'scaler': scaler,\n",
    "    'encoder': encoder,\n",
    "    'input_cols': input_cols,\n",
    "    'target_col': target_col,\n",
    "    'numeric_cols': numeric_cols,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'encoded_cols': encoded_cols,\n",
    "    'train_inputs': train_inputs,\n",
    "    'train_raw_df': train_df\n",
    "}\n",
    "\n",
    "joblib.dump(aussie_rain, 'weather_model_dt.joblib', compress=('zlib', 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
