{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Давайте подивимося, як LSTM можна використовувати для побудови нейронної мережі прогнозування часових.\n",
    "\n",
    "Будемо працювати з задачею прогнозування кількості пасажирів міжнародних авіаліній. З цим набором даних ми вже працювали в лекції \"Time Series Analysis\" і ви зможете порівняти результати :)\n",
    "\n",
    "Задача полягає в тому, щоб за заданими роком і місяцем передбачити кількість пасажирів міжнародних авіаліній в одиницях виміру 1,000. Дані охоплюють період з січня 1949 року по грудень 1960 року, тобто 12 років, зі 144 спостереженнями.\n",
    "\n",
    "Це регресійна задача. Тобто, знаючи кількість пасажирів (в тисячах) за останні місяці, можна передбачити, якою буде кількість пасажирів у наступному місяці. Набір даних має лише одну характеристику: \"Кількість пасажирів\" - `Passengers`.\n",
    "\n",
    "Далі вже наведений код для читання даних, але нам їх ще треба буде трошки обробити."
   ],
   "metadata": {
    "id": "QVNVsLwJvV9S"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hw3dGYsyluYm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "outputId": "a3a3b30e-a1a9-4d28-dd1a-3e5b5e242206",
    "ExecuteTime": {
     "end_time": "2025-05-04T18:27:01.473866Z",
     "start_time": "2025-05-04T18:26:59.373124Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Завантаження даних\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.set_index('Month', inplace=True)\n",
    "display(df.head())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Passengers\n",
       "Month              \n",
       "1949-01         112\n",
       "1949-02         118\n",
       "1949-03         132\n",
       "1949-04         129\n",
       "1949-05         121"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passengers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1949-01</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-02</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-04</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-05</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 1.** Створіть змінну типу `numpy.ndarray`, яка містить значення кількості пасажирів в форматі `float32`. Такий формат даних нам треба для тренування нейромережі."
   ],
   "metadata": {
    "id": "BCcNvF28wSH3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "passengers = df['Passengers'].to_numpy(dtype='float32')\n",
    "\n",
    "passengers"
   ],
   "metadata": {
    "id": "7PcJkPAoBOH5",
    "ExecuteTime": {
     "end_time": "2025-05-04T18:38:30.204619Z",
     "start_time": "2025-05-04T18:38:30.199887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112., 118., 132., 129., 121., 135., 148., 148., 136., 119., 104.,\n",
       "       118., 115., 126., 141., 135., 125., 149., 170., 170., 158., 133.,\n",
       "       114., 140., 145., 150., 178., 163., 172., 178., 199., 199., 184.,\n",
       "       162., 146., 166., 171., 180., 193., 181., 183., 218., 230., 242.,\n",
       "       209., 191., 172., 194., 196., 196., 236., 235., 229., 243., 264.,\n",
       "       272., 237., 211., 180., 201., 204., 188., 235., 227., 234., 264.,\n",
       "       302., 293., 259., 229., 203., 229., 242., 233., 267., 269., 270.,\n",
       "       315., 364., 347., 312., 274., 237., 278., 284., 277., 317., 313.,\n",
       "       318., 374., 413., 405., 355., 306., 271., 306., 315., 301., 356.,\n",
       "       348., 355., 422., 465., 467., 404., 347., 305., 336., 340., 318.,\n",
       "       362., 348., 363., 435., 491., 505., 404., 359., 310., 337., 360.,\n",
       "       342., 406., 396., 420., 472., 548., 559., 463., 407., 362., 405.,\n",
       "       417., 391., 419., 461., 472., 535., 622., 606., 508., 461., 390.,\n",
       "       432.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Очікуваний результат:\n",
    "```array([112., 118., 132., 129., 121.], dtype=float32)```"
   ],
   "metadata": {
    "id": "Vms2Pxp1xCrB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 2**. Розбийте дані на тренувальні і валідаційні у співвідношенні 67% йде у тренування, 33 - у валідацію. Памʼятаємо, що ми працюємо з tim series, відповідно, навчаємось на давніших, валідуємось - на новіших."
   ],
   "metadata": {
    "id": "vESTxq-OxLRK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "split_index = int(len(passengers) * 0.67)\n",
    "\n",
    "train = passengers[:split_index]\n",
    "test = passengers[split_index:]"
   ],
   "metadata": {
    "id": "USpGte_tBPR1",
    "ExecuteTime": {
     "end_time": "2025-05-04T19:32:27.352106Z",
     "start_time": "2025-05-04T19:32:27.349701Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 3**.\n",
    "\n",
    "Реалізуйте функцію `create_dataset`, яка перетворить одномірний часовий ряд (набір даних) у формат, придатний для тренування нейромережі.\n",
    "\n",
    "Функція повинна приймати два аргументи:\n",
    "- `dataset` — numpy-масив часового ряду,\n",
    "- `lookback` — кількість попередніх кроків, які використовуватимуться для передбачення.\n",
    "\n",
    "Функція повинна повернути два **тензори** PyTorch:\n",
    "- `X` — набір ознак (вікно попередніх значень),\n",
    "- `y` — цільові значення (наступні після вікна кроки).\n",
    "\n",
    "Дані ми будемо подавати моделі в наступному форматі:\n",
    "`\n",
    "tensor([[112.],\n",
    "        [118.],\n",
    "        [132.],\n",
    "        [129.],\n",
    "        [121.]])\n",
    "`\n",
    "Відповідно першою розмірністю буде йти розмір вхідного батча, а другою - розмір вхіднизх даних і в нас це 1, бо лише одне значення на вході щоразу.\n",
    "\n",
    "Після виконання завдання запустіть код нижче. Ми будемо передбачати на основі кількості пасажирів в попередній день кількість пасажирів в наступний, тому `lookback == 1`."
   ],
   "metadata": {
    "id": "YB-e-vEDx3bn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def create_dataset(dataset: np.array, lookback_steps: int = 1):\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(len(dataset) - lookback_steps):\n",
    "        X.append(dataset[i: i + lookback_steps])\n",
    "        y.append(dataset[i + lookback_steps])\n",
    "\n",
    "    X = torch.tensor(np.array(X), dtype=torch.float32).view(-1, lookback_steps)\n",
    "    y = torch.tensor(np.array(y), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X, y"
   ],
   "metadata": {
    "id": "s5UXOiAHBVwe",
    "ExecuteTime": {
     "end_time": "2025-05-04T19:41:12.248930Z",
     "start_time": "2025-05-04T19:41:12.246188Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "lookback = 1\n",
    "X_train, y_train = create_dataset(train, lookback_steps=lookback)\n",
    "X_test, y_test = create_dataset(test, lookback_steps=lookback)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dA8FwOfwuPyl",
    "outputId": "b4bd6a9a-f611-4f81-eceb-7c9e17c8dab6",
    "ExecuteTime": {
     "end_time": "2025-05-04T19:43:49.829378Z",
     "start_time": "2025-05-04T19:43:49.825949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95, 1]) torch.Size([95, 1])\n",
      "torch.Size([47, 1]) torch.Size([47, 1])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "Очікуваний результат:\n",
    "```\n",
    "torch.Size([95, 1]) torch.Size([95, 1])\n",
    "torch.Size([47, 1]) torch.Size([47, 1])\n",
    "```"
   ],
   "metadata": {
    "id": "dvEA-D-SzcWf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 4**.\n",
    "\n",
    "Зверніть увагу на розмірності в попередньому завданні.\n",
    "З допомогою модуля `torch.nn` опишіть клас `AirModel`, який є нейронною мережею для прогнозування кількості пасажирів за допомогою LSTM.\n",
    "\n",
    "1. **Конструктор класу** повинен приймати параметри `hidden_size`, `num_layers` та ініціювати шари:\n",
    "   - LSTM-шар з наступними параметрами:\n",
    "     - `input_size` — кожна точка часового ряду є окремим входом,,\n",
    "     - `hidden_size` — заданий в конструкторі класу мережі,\n",
    "     - `num_layers=1` — кількість шарів LSTM, задана в конструкторі мережі,\n",
    "     - `batch_first=True` — визначає, що першим виміром є розмір батчу.\n",
    "   - Лінійний шар (`nn.Linear`) для перетворення виходу LSTM на прогноз однієї точки.\n",
    "\n",
    "2. **Метод forward** повинен виконувати наступні дії:\n",
    "   - Передати вхідний тензор через LSTM-шар і отримати виходи (ігноруючи приховані стани).\n",
    "   - Пропустити вихід LSTM через лінійний шар для отримання остаточного прогнозу.\n",
    "\n",
    "Створіть об'єкт класу `AirModel` зі значеннями параметрів `hidden_size=50`, `num_layers=1` і протестуйте роботу моделі на вхідному тензорі `tensor([[112.]])`. На цьому етапі ми маємо переконатись, що модель здатна генерувати передбачення з рандомно ініційованими вагами."
   ],
   "metadata": {
    "id": "eeiFJ-jDznj5"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "dcafrsmrDHsz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 5**.\n",
    "\n",
    "Створіть об'єкт DataLoader для завантаження даних, використовуючи тренувальні вибірки `X_train` та `y_train`. Ваш DataLoader повинен виконувати наступні вимоги:\n",
    "\n",
    "1. Використовувати клас `TensorDataset`, щоб об'єднати тензори ознак `X_train` і цільових значень `y_train`.\n",
    "2. Дані повинні завантажуватися невеликими батчами розміром 8 за допомогою параметра `batch_size`.\n",
    "3. Використовувати параметр `shuffle=True`, щоб дані перемішувалися перед кожною епохою тренування.\n"
   ],
   "metadata": {
    "id": "-R6zv9nu2tWB"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "WKdkptY7DMAc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 6**.\n",
    "\n",
    "1. Реалізуйте навчання нейронної мережі `AirModel` для прогнозування часових рядів, використовуючи Adam-оптимізатор та функцію втрат MSE (середньоквадратичну похибку).\n",
    "2. Створіть цикл тренування для 2000 епох, у якому на кожній епосі:\n",
    "   - Виконуйте крок тренування моделі (прямий прохід, обчислення похибки, зворотний прохід і оновлення ваг).\n",
    "   - Підраховуйте середню похибку на кожному батчі даних і зберігайте її у списку `losses`.\n",
    "3. Раз на 100 епох проводьте валідацію моделі:\n",
    "   - Перевіряйте модель на тренувальних та тестових даних без оновлення ваг.\n",
    "   - Обчислюйте корінь середньоквадратичної похибки (RMSE) для тренувальної та тестової вибірок і виводьте результати на екран.\n",
    "   \n",
    "**Примітка:**\n",
    "- Використовуйте вже створений `DataLoader` для отримання батчів даних.\n",
    "- Валідацію виконуйте в режимі `eval()`, вимикаючи обчислення градієнтів з `torch.no_grad()`.\n",
    "\n",
    "**Приклад виходу:**\n",
    "```\n",
    "Epoch 0: train RMSE 12.3456, test RMSE 15.6789\n",
    "Epoch 100: train RMSE 9.8765, test RMSE 12.3456\n",
    "...\n",
    "```"
   ],
   "metadata": {
    "id": "6ZaGh7IF2nfT"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "pEVnWusrDNTt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 7.** Побудуйте графік лосів. Зробіть висновок з графіку, чи навчилась модель?"
   ],
   "metadata": {
    "id": "m0sIo4kp5X_s"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "AS2USLRq76up"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Модель навчилась, але не факт, що точно)"
   ],
   "metadata": {
    "id": "8eBoUQVB5p0h"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Доволі неочікувано, що середньоквадратичне відхилення тестового набору даних буде на порядок більшим за одиниці в нашому наборі даних. Середньоквадратичне відхилення 100 означає, що прогноз і фактичне значення будуть відрізнятися в середньому на 100 (тобто, 100 000 пасажирів у цьому наборі даних).\n",
    "\n"
   ],
   "metadata": {
    "id": "-vCiGfQw7sEK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Щоб краще зрозуміти якість прогнозу, ви можете побудувати графік з кодом нижче (а ще нижче - описано, що відбувається в цьому коді, бо це теж корисно зрозуміти):"
   ],
   "metadata": {
    "id": "bgtO7NZh77vU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_predicts():\n",
    "  with torch.no_grad():\n",
    "      # Зсув прогнозів для тренувальних даних\n",
    "      train_plot = np.ones_like(timeseries) * np.nan\n",
    "      y_pred = model(X_train)\n",
    "      y_pred = y_pred[:, -1]\n",
    "      train_plot[lookback:train_size] = model(X_train)[:, -1]\n",
    "\n",
    "      # Зсув прогнозів для тестових даних\n",
    "      test_plot = np.ones_like(timeseries) * np.nan\n",
    "      test_plot[train_size+lookback:len(timeseries)] = model(X_test)[:, -1]\n",
    "\n",
    "  # Візуалізація результатів\n",
    "  plt.plot(timeseries, c='b')  # Реальні дані\n",
    "  plt.plot(train_plot, c='r')  # Прогнози на тренувальних даних\n",
    "  plt.plot(test_plot, c='g')   # Прогнози на тестових даних\n",
    "  plt.show()\n",
    "\n",
    "plot_predicts()"
   ],
   "metadata": {
    "id": "ZznU2AK0vES5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Що відбувається в коді вище.** В цьому коді здійснюється процес прогнозування часових рядів за допомогою LSTM моделі, а також виведення графіку, який показує реальні значення, тренувальні та тестові прогнози. Ось що відбувається на кожному етапі:\n",
    "\n",
    "1. **`torch.no_grad()`**: Цей контекстний менеджер вимикає обчислення градієнтів, що означає, що під час прогнозування не будуть зберігатися проміжні обчислення для зворотного проходу (backpropagation). Це підвищує ефективність під час прогнозування і зменшує використання пам'яті.\n",
    "\n",
    "2. **Зсув прогнозів для тренувальних даних:**\n",
    "   - Створюється масив `train_plot`, який має такий самий розмір, як і часовий ряд (`timeseries`), і заповнюється значеннями NaN (`np.nan`), щоб залишити місце для реальних значень.\n",
    "   - Модель передбачає виходи для тренувальних даних `X_train`.\n",
    "   - Використовується лише останнє передбачене значення для кожного входу LSTM (`y_pred[:, -1]`).\n",
    "   - Прогнози зсуваються, починаючи з індексу `lookback` до кінця тренувальних даних (індекс `train_size`). Цей зсув потрібен, щоб зробити прогноз на основі попередніх даних і відобразити його на правильній частині графіку.\n",
    "\n",
    "3. **Зсув прогнозів для тестових даних:**\n",
    "   - Створюється масив `test_plot`, який також заповнюється NaN.\n",
    "   - Прогнози для тестових даних додаються з індексу `train_size + lookback` до кінця реальних даних, щоб відобразити, де модель починає прогнозувати тестову вибірку.\n",
    "\n",
    "4. **Побудова графіка:**\n",
    "   - `plt.plot(timeseries, c='b')`: Виводить реальні значення часового ряду (синя лінія).\n",
    "   - `plt.plot(train_plot, c='r')`: Виводить тренувальні прогнози (червона лінія).\n",
    "   - `plt.plot(test_plot, c='g')`: Виводить тестові прогнози (зелена лінія).\n",
    "\n",
    "**Чому це робиться:**\n",
    "- Зсув прогнозів для тренувальних і тестових даних дозволяє візуально зрівняти, наскільки добре модель прогнозує як на тренувальній, так і на тестовій вибірках. Зазвичай, червона лінія (тренувальні прогнози) повинна точно відповідати синій лінії (реальні дані), а зелена лінія (тестові прогнози) дає змогу побачити, наскільки модель добре працює на нових даних, яких вона раніше не бачила."
   ],
   "metadata": {
    "id": "ahPW3iiJDg1R"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Завдання 8**. Навчіть модель з hidden_size=100 та порівняйте результати прогнозів з попередніми."
   ],
   "metadata": {
    "id": "PhoeHLus-xIr"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "92032N_E_PxY"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
