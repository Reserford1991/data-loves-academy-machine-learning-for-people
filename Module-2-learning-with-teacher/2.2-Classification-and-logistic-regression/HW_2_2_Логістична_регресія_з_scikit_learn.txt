import os

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings("ignore")
from sklearn.preprocessing import MinMaxScaler

clients_df = pd.read_csv('csv/train.csv')

clients_df.head()

clients_df.info()

# clients_df['CustomerId'] = clients_df['CustomerId'].astype(int)
clients_df.drop(['CustomerId'], axis=1, inplace=True)
clients_df.head()

clients_df.info()

use_sample = False

train_val_df, test_df = train_test_split(clients_df, test_size=0.2, random_state=42)
train_df, val_df = train_test_split(clients_df, test_size=0.25, random_state=42)

print('train_df.shape:', train_df.shape)
print('val_df.shape:', val_df.shape)
print('test_df.shape:', test_df.shape)

input_cols = list(train_df.columns)[1:-1]
target_col = 'Exited'

print(input_cols)
print(target_col)

train_inputs = train_df[input_cols].copy()
train_targets = train_df[target_col].copy()

val_inputs = val_df[input_cols].copy()
val_targets = val_df[target_col].copy()

test_inputs = test_df[input_cols].copy()
test_targets = test_df[target_col].copy()

numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()
categorical_cols = train_inputs.select_dtypes('object').columns.tolist()

numeric_cols, categorical_cols

if 'Surname' in train_inputs:
    train_inputs.drop(['Surname'], axis=1, inplace=True)
if 'Surname' in val_inputs:
    val_inputs.drop(['Surname'], axis=1, inplace=True)
if 'Surname' in test_inputs:
    test_inputs.drop(['Surname'], axis=1, inplace=True)
if 'Surname' in categorical_cols:
    categorical_cols.remove('Surname')

print(train_inputs.info())

train_inputs['Gender'].unique()

train_inputs['Geography'].unique()

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoder.fit(train_inputs[categorical_cols])

encoder.categories_

encoded_cols = list(encoder.get_feature_names_out(categorical_cols))
print(encoded_cols)

encoder.transform(train_inputs[categorical_cols])[:10]

train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])
val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])
test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])

# Також приберу оригінальні колонки, щоб вони не заважали навчанню моделі
if 'Geography' in train_inputs:
    train_inputs.drop(['Geography'], axis=1, inplace=True)
if 'Geography' in val_inputs:
    val_inputs.drop(['Geography'], axis=1, inplace=True)
if 'Geography' in test_inputs:
    test_inputs.drop(['Geography'], axis=1, inplace=True)

if 'Gender' in train_inputs:
    train_inputs.drop(['Gender'], axis=1, inplace=True)
if 'Gender' in val_inputs:
    val_inputs.drop(['Gender'], axis=1, inplace=True)
if 'Gender' in test_inputs:
    test_inputs.drop(['Gender'], axis=1, inplace=True)

pd.set_option('display.max_columns', None)
train_inputs

def column_description(column_name):
    print(train_inputs[column_name])

    # Histohram
    plt.hist(train_inputs[column_name], bins=30, edgecolor='black')
    plt.xlabel(column_name)
    plt.ylabel('Count')
    plt.title(f'Distribution of {column_name}')
    plt.show()

    # Density Plot
    sns.kdeplot(data=train_inputs, x=column_name, shade=True)
    plt.title(f'{column_name} Density')
    plt.show()

    # Box plot
    sns.boxplot(data=train_inputs, x=column_name)
    plt.title(f'Box Plot of {column_name}')
    plt.show()


    # Empty values
    credit_null = train_inputs[column_name].isnull()
    counts = credit_null.value_counts()  # how many True, how many False
    counts.plot(kind='bar', color=['orange','green'])
    plt.xticks([0,1], ['Not Null', 'Null'], rotation=0)  # rename ticks for clarity
    plt.title(f'Null vs Not Null for {column_name}')
    plt.ylabel('Count')
    plt.show()

    zero_counts = train_inputs[column_name] == 0
    counts = zero_counts.value_counts()  # how many True, how many False
    counts.plot(kind='bar', color=['orange','green'])
    plt.xticks([0,1], ['Not 0', '0'], rotation=0)  # rename ticks for clarity
    plt.title(f'0 vs Not 0 for {column_name}')
    plt.ylabel('Count')
    plt.show()

column_description('CreditScore')

column_description('Balance')

column_description('EstimatedSalary')

column_description('Age')

train_inputs.head()

column_description('Tenure')

train_inputs['Tenure'].head()

column_description('NumOfProducts')

train_inputs['NumOfProducts'].head()

column_description('HasCrCard')

scaler = MinMaxScaler()

scaler.fit(train_inputs[numeric_cols])

train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols])
val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols])
test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])

train_inputs[numeric_cols].describe().round(2)

train_inputs.head()

%time
train_inputs.to_parquet('parquet/train_inputs.parquet')
val_inputs.to_parquet('parquet/val_inputs.parquet')
test_inputs.to_parquet('parquet/test_inputs.parquet')

os.listdir('./parquet')

from sklearn.linear_model import LogisticRegression
model = LogisticRegression(solver='liblinear')

model.fit(train_inputs[numeric_cols + encoded_cols], train_targets)

X_train = train_inputs[numeric_cols + encoded_cols]
X_val = val_inputs[numeric_cols + encoded_cols]
X_test = test_inputs[numeric_cols + encoded_cols]

X_train.head()

plt.figure(figsize=(20,10))
sns.heatmap(X_train.corr(),annot=True,cmap="coolwarm")

plt.figure(figsize=(20,10))
sns.heatmap(X_val.corr(),annot=True,cmap="coolwarm")

from sklearn.metrics import f1_score

preds = model.predict(X_train)
preds[:5], train_targets[:5]

f1_score(train_targets, preds, pos_label=1)

def get_f1_score(inputs, targets, name=''):
  preds = model.predict(inputs)

  f1_score_ = f1_score(targets, preds, pos_label=1)
  print(f"F1 score {name}: {f1_score_:.2f}%")

get_f1_score(X_train, train_targets, 'Training')
get_f1_score(X_val, val_targets, 'Validation')
get_f1_score(X_test, test_targets, 'Test')


from sklearn.metrics import roc_curve, auc

def compute_auroc_and_build_roc(inputs, targets, name=''):
  # Predict probabilities
  y_pred_proba = model.predict_proba(inputs)[:, 1]

  # Compute ROC curve
  fpr, tpr, thresholds = roc_curve(targets, y_pred_proba, pos_label=1)

    # Compute AUROC
  roc_auc = auc(fpr, tpr)
  print(f'AUROC for {name}: {roc_auc:.2f}')

  # Plot the ROC curve
  plt.figure()
  plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
  plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.05])
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title(f'Receiver Operating Characteristic (ROC) Curve for {name}')
  plt.legend(loc="lower right")
  plt.show()

compute_auroc_and_build_roc(X_train, train_targets, 'Training')
compute_auroc_and_build_roc(X_val, val_targets, 'Validation')

train_df['Exited'].value_counts()

train_preds = model.predict(X_train)
train_preds

train_targets

train_probs = model.predict_proba(X_train)
train_probs


np.argmax(train_probs, axis=1)

plt.hist(train_probs[:,1])

(train_probs[:,1][:20]>0.2).astype(int)

(train_probs[:,1][:20]>0.5).astype(int)

train_probs[:,1].round(2)[:20]

train_targets.value_counts(normalize=True)

model.classes_

from sklearn.metrics import accuracy_score

accuracy_score(train_targets, train_preds)

from sklearn.metrics import confusion_matrix
confusion_matrix(train_targets, train_preds)


def predict_and_plot(inputs, targets, name=''):
    preds = model.predict(inputs)

    accuracy = accuracy_score(targets, preds)
    print("Accuracy: {:.2f}%".format(accuracy * 100))

    cf = confusion_matrix(targets, preds, normalize='true')
    plt.figure()
    sns.heatmap(cf, annot=True)
    plt.xlabel('Prediction')
    plt.ylabel('Target')
    plt.title('{} Confusion Matrix'.format(name))

    return preds

    train_preds = predict_and_plot(X_train, train_targets, 'Training')

    val_preds = predict_and_plot(X_val, val_targets, 'Validation')

    test_preds = predict_and_plot(X_test, test_targets, 'Test')

    def random_guess(inputs):
    return np.random.choice([0, 1], len(inputs))
d   ef all_no(inputs):
    return np.full(len(inputs), 0)


 accuracy_score(test_targets, random_guess(X_test))
 accuracy_score(test_targets, all_no(X_test))

 import joblib

churn_prediction = {
    'model': model,
    'scaler': scaler,
    'encoder': encoder,
    'input_cols': input_cols,
    'target_col': target_col,
    'numeric_cols': numeric_cols,
    'categorical_cols': categorical_cols,
    'encoded_cols': encoded_cols,
}

joblib.dump(churn_prediction, 'models/churn_prediction.joblib')

model_2 = joblib.load('models/churn_prediction.joblib')

def predict_raw_df(scaler, encoder, numeric_cols, categorical_cols, input_df: pd.DataFrame):
    # input_df['Age'] = input_df['Age'].astype(int)
    # input_df['Tenure'] = input_df['Tenure'].astype(int)
    # input_df['NumOfProducts'] = input_df['NumOfProducts'].astype(int)
    # input_df['HasCrCard'] = input_df['HasCrCard'].astype(int)

    input_df[numeric_cols] = scaler.transform(input_df[numeric_cols])


    input_df[encoded_cols] = encoder.transform(input_df[categorical_cols])

    if 'Surname' in input_df:
        input_df.drop(['Surname'], axis=1, inplace=True)
    if 'Surname' in categorical_cols:
        categorical_cols.remove('Surname')

    if 'Geography' in input_df:
        input_df.drop(['Geography'], axis=1, inplace=True)

    if 'Gender' in input_df:
        input_df.drop(['Gender'], axis=1, inplace=True)

    X_input = input_df[numeric_cols + encoded_cols]

    prob = model.predict_proba(X_input)
    return prob

    test_raw_df = pd.read_csv('csv/test.csv')

predictions = predict_raw_df(scaler, encoder, numeric_cols, categorical_cols, test_raw_df)
exited_predictions = np.argmax(predictions, axis=1)
test_raw_df['Exited'] = exited_predictions


sample_submission_df = pd.read_csv('csv/sample_submission.csv')

merged_df = sample_submission_df.merge(
    test_raw_df[['id', 'Exited']],
    on='id',
    how='left'
)

# Remove 'Exited_x' and rename 'Exited_y' => 'Exited'
merged_df = merged_df.drop(columns=['Exited_x'])
merged_df = merged_df.rename(columns={'Exited_y': 'Exited'})

merged_df.to_csv('csv/submission.csv', index=False)

merged_df


# merged_df['Exited'] = merged_df['prediction']
# merged_df = merged_df.drop(columns=['prediction'])